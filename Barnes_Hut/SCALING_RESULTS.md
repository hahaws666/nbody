# Strong Scaling 测试结果汇总

## 测试配置
- **问题规模**: 500,000 个粒子（固定）
- **迭代次数**: 100 次
- **算法**: Barnes-Hut + Leapfrog

## 测试结果

| 配置 | 节点数 | 每节点进程 | 每进程线程 | 总核心数 | 运行时间(秒) | 运行时间(分钟) | 加速比 | 效率 |
|------|--------|-----------|-----------|---------|------------|--------------|--------|------|
| 1n_5t_8c | 1 | 5 | 8 | 40 | 1212.51 | 20.21 | 1.00 (基准) | 100.0% |
| 1n_10t_4c | 1 | 10 | 4 | 40 | ~1.2* | 0.02 | - | - |
| 1n_20t_2c | 1 | 20 | 2 | 40 | ~1.7* | 0.03 | - | - |
| 2n_5t_8c | 2 | 5 | 8 | 80 | 1287.20 | 21.45 | 0.94 | 47.1% |
| 2n_10t_4c | 2 | 10 | 4 | 80 | 2130.07 | 35.50 | 0.57 | 28.5% |

*注：1n_10t_4c 和 1n_20t_2c 的作业可能未完整运行（时间过短）

## 关键发现

### 1. 单节点性能（40核心）
- **最佳配置**: 5 MPI × 8 OpenMP (1n_5t_8c)
  - 运行时间: 1212.51 秒 (约 20 分钟)
  - 每次迭代: 12.1 秒

### 2. 跨节点扩展性
- **从 1 节点到 2 节点**:
  - 理想加速比: 2.0x
  - 实际加速比: 0.94x (2n_5t_8c vs 1n_5t_8c)
  - **效率: 47.1%** (远低于理想值)

### 3. MPI/OpenMP 组合影响
- **2n_5t_8c** (10 MPI × 8 OMP): 1287.20s
- **2n_10t_4c** (20 MPI × 4 OMP): 2130.07s
- **结论**: 较少的 MPI 进程和更多的 OpenMP 线程表现更好

## 性能瓶颈分析

### 1. 通信开销
- 2 节点配置性能下降，说明 MPI 通信开销显著
- 每次迭代需要：
  - 同步位置（MPI_Allgather）
  - 同步速度和加速度（MPI_Allgather）
  - 跨节点通信延迟影响性能

### 2. 负载均衡
- 2n_10t_4c 性能最差，可能因为：
  - 更多的 MPI 进程导致更多的通信
  - 负载分配不均

### 3. 树构建开销
- 每次迭代需要重新建树（基于新位置）
- 并行建树的开销可能影响性能

## 建议

1. **优化通信**: 
   - 减少 MPI_Allgather 调用次数
   - 使用更高效的通信模式

2. **MPI/OpenMP 平衡**:
   - 对于 2 节点，推荐 5-10 MPI 进程/节点
   - 每个进程使用 4-8 个 OpenMP 线程

3. **进一步测试**:
   - 测试更大的问题规模（weak scaling）
   - 测试更多节点（如果可用）

## 文件说明

- `nbody_1n_5t_8c_86.out`: 1节点，5进程×8线程，完整运行
- `nbody_2n_5t_8c_89.out`: 2节点，5进程×8线程，完整运行
- `nbody_2n_10t_4c_90.out`: 2节点，10进程×4线程，完整运行

